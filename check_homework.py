import streamlit as st
import pandas as pd
import re
import io
import os
import datetime
import hashlib
from pathlib import Path

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="ä½œä¸šå¤šç»´åº¦åˆ†æç³»ç»Ÿ", layout="wide")
st.title("ğŸ“ ä½œä¸šæäº¤å¤šç»´åº¦åˆ†æç³»ç»Ÿ")

# --- æ ¸å¿ƒå¤„ç†å‡½æ•° ---
def extract_id(filename):
    """ä»æ–‡ä»¶åæå–9ä½å­¦å·"""
    match = re.search(r'\d{9}', filename)
    return match.group() if match else None

def calculate_file_md5(file_path):
    """è¯»å–æœ¬åœ°æ–‡ä»¶å¹¶è®¡ç®—MD5"""
    hash_md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except:
        return None

def get_roster_from_path(file_path):
    """è¯»å–æœ¬åœ°ExcelèŠ±åå†Œ"""
    try:
        # æŒ‡å®šå¼•æ“ä»¥é˜²äº‘ç«¯æˆ–éƒ¨åˆ†ç¯å¢ƒç¼ºå¤±
        df = pd.read_excel(file_path, engine='openpyxl')
        sid_idx = next((i for i, col in enumerate(df.columns) if 'å­¦å·' in str(col)), None)
        if sid_idx is None:
            for i, col in enumerate(df.columns):
                if any(re.search(r'\d{9}', str(v)) for v in df[col].dropna().head(5)):
                    sid_idx = i
                    break
        if sid_idx is None: return None, "Excelä¸­æœªæ‰¾åˆ°å­¦å·åˆ—"
        
        name_idx = sid_idx + 1
        roster = {}
        for _, row in df.iterrows():
            sid_match = re.search(r'\d{9}', str(row[df.columns[sid_idx]]))
            if sid_match:
                s_id = sid_match.group()
                s_name = str(row[df.columns[name_idx]]) if name_idx < len(df.columns) else "æœªçŸ¥"
                roster[s_id] = s_name
        return roster, None
    except Exception as e:
        return None, str(e)

# --- ä¾§è¾¹æ ï¼šè·¯å¾„è¾“å…¥åŒº ---
with st.sidebar:
    st.image('https://tse3.mm.bing.net/th/id/OIP.eVdPo2CI6WY3vDM14PsTYQHaFy?rs=1&pid=ImgDetMain&o=7&rm=3')
    st.header("ğŸ“ æœ¬åœ°è·¯å¾„è®¾ç½®")
    st.info("è¯·åœ¨ä¸‹æ–¹è¾“å…¥ç”µè„‘é‡Œçš„æ–‡ä»¶å¤¹è·¯å¾„")
    
    # æ‰‹åŠ¨è¾“å…¥è·¯å¾„
    roster_path = st.text_input("1. èŠ±åå†Œæ–‡ä»¶è·¯å¾„", value=r"C:\Users\Documents\èŠ±åå†Œ.xlsx")
    hw_folder_path = st.text_input("2. ä½œä¸šæ–‡ä»¶å¤¹è·¯å¾„", value=r"C:\Users\Documents\å­¦ç”Ÿä½œä¸š")
    
    st.divider()
    st.header("âš™ï¸ ä»»åŠ¡è®¾ç½®")
    deadline_date = st.date_input("æˆªæ­¢æ—¥æœŸ", datetime.date.today())
    deadline_time = st.time_input("æˆªæ­¢æ—¶é—´", datetime.time(23, 59))
    deadline = datetime.datetime.combine(deadline_date, deadline_time)

# --- ä¸»ç•Œé¢é€»è¾‘ ---
if os.path.exists(roster_path) and os.path.exists(hw_folder_path):
    roster_dict, err = get_roster_from_path(roster_path)
    
    if err:
        st.error(f"èŠ±åå†Œè¯»å–å¤±è´¥: {err}")
    else:
        all_roster_ids = set(roster_dict.keys())
        analysis = {"valid": {}, "unknown": [], "similarity": {}}

        # éå†æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        files = [f for f in os.listdir(hw_folder_path) if os.path.isfile(os.path.join(hw_folder_path, f))]
        
        for fname in files:
            full_path = os.path.join(hw_folder_path, fname)
            sid = extract_id(fname)
            
            # --- å…³é”®ï¼šè¯»å–æœ¬åœ°æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´ ---
            mtime_ts = os.path.getmtime(full_path)
            mtime = datetime.datetime.fromtimestamp(mtime_ts)
            is_late = mtime > deadline
            
            md5_hash = calculate_file_md5(full_path)
            
            file_info = {
                "name": fname,
                "time": mtime,
                "is_late": is_late,
                "md5": md5_hash,
                "size": os.path.getsize(full_path)
            }

            if not sid or sid not in all_roster_ids:
                analysis["unknown"].append(file_info)
            else:
                analysis["valid"].setdefault(sid, []).append(file_info)
            
            if md5_hash:
                analysis["similarity"].setdefault(md5_hash, []).append(file_info)

        # --- æ•°æ®å±•ç¤º ---
        st.divider()
        sub_count = len(analysis["valid"])
        total_count = len(all_roster_ids)
        
        c1, c2, c3 = st.columns(3)
        c1.metric("åº”äº¤äººæ•°", total_count)
        c2.metric("å·²äº¤äººæ•°", sub_count)
        c3.metric("å®Œæˆç‡", f"{int(sub_count/total_count*100) if total_count else 0}%")
        st.progress(sub_count/total_count if total_count else 0)

        t1, t2, t3, t4 = st.tabs(["âŒ æœªäº¤åå•", "âœ… å·²äº¤è¯¦æƒ…", "â“ å¼‚å¸¸/é‡å¤", "â€¼ ç›¸ä¼¼åº¦åˆç­›"])

        with t1:
            missing_ids = sorted(list(all_roster_ids - set(analysis["valid"].keys())))
            if missing_ids:
                df_m = pd.DataFrame([{"å­¦å·": i, "å§“å": roster_dict[i]} for i in missing_ids])
                st.dataframe(df_m, use_container_width=True)
            else:
                st.success("ğŸ‰ å…¨å‘˜äº¤é½ï¼")

        with t2:
            done_data = []
            for sid, f_list in analysis["valid"].items():
                f = max(f_list, key=lambda x: x["time"]) # è‡ªåŠ¨å–æœ€åä¿®æ”¹çš„ç‰ˆæœ¬
                done_data.append({
                    "å­¦å·": sid, "å§“å": roster_dict[sid],
                    "æœ€åä¿®æ”¹æ—¶é—´": f["time"].strftime('%Y-%m-%d %H:%M'),
                    "çŠ¶æ€": "â° è¿Ÿäº¤" if f["is_late"] else "æ­£å¸¸",
                    "æ–‡ä»¶å": f["name"]
                })
            st.dataframe(pd.DataFrame(done_data).sort_values("å­¦å·"), use_container_width=True)

        with t3:
            col_a, col_b = st.columns(2)
            with col_a:
                st.subheader("ğŸ˜… å¼‚å¸¸æ–‡ä»¶")
                for f in analysis["unknown"]: st.write(f"- {f['name']}")
            with col_b:
                st.subheader("ğŸ‘¥ğŸ‘¥ é‡å¤æäº¤")
                for sid, flist in analysis["valid"].items():
                    if len(flist) > 1: st.warning(f"{sid} ({roster_dict[sid]}) æœ‰ {len(flist)} ä¸ªç‰ˆæœ¬")

        with t4:
            st.subheader("ğŸ¤«ğŸ¤«ğŸ¤« å†…å®¹å®Œå…¨ä¸€è‡´æ£€æµ‹")
            for md5, flist in analysis["similarity"].items():
                if len(flist) > 1:
                    st.error(f"å‘ç°é‡å¤å†…å®¹ï¼š")
                    for f in flist: st.write(f"  - {f['name']}")

else:
    st.info("ğŸ” è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥æ­£ç¡®çš„ã€èŠ±åå†Œè·¯å¾„ã€‘å’Œã€ä½œä¸šæ–‡ä»¶å¤¹è·¯å¾„ã€‘ã€‚")
